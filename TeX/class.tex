\newpage
\section{Исследование архитектур для классификации объектов на изображении}
В данной главе представлено сравнение выбранных архитектур по числу слоёв, настраиваемых параметров, качеству работы на разных задачах.

Так как данные архитектуры уже обучены на задаче ImageNet1000 и умеют выделять признаки объектов, то для классификации на других данных они не обучаются заново, а используются предобученные модели. Все слои кроме полносвязного замораживаются для изменений, а полносвязный слой обучается с учётом необходимого количества классов.

Для исследования в данной работе используется python с библиотекой pytorch.

\subsection{Сравнение архитектур}
Для сравнения архитектур были загружены готовые модели, реализован подробный вывод структуры, подсчёт общего количества обучаемых параметров и количества параметров по слоям (Приложение~А).

\subsubsection{ResNet-18}
На первом уровне ResNet-18 использует свёртку 7x7 с шагом 2, чтобы уменьшить входной сигнал до порядка, аналогично уровню пула. Затем следуют два residual блока перед повторной понижающей дискретизацией на 2. Уровень понижающей дискретизации также является слоем свёртки. Так продолжается ещё несколько раз. После применяется average pooling, который создаёт 512 признаков, усредняя данные каждой свёртки. Последний слой - полносвязный. В результате получается 1000-мерный вектор, который затем подаётся в слой Softmax.
\\

Архитектура по слоям:\\
1. свёрточный слой $7\times7\times64$ + слой батч-нормализации\\
Max pool\\
2--5. свёрточные слои $\begin{bmatrix}
3\times3\times64\\
3\times3\times64\\
\end{bmatrix} \times2$ + слои батч-нормализации\\
6--9. свёрточные слои $\begin{bmatrix}
3\times3\times128\\
3\times3\times128\\
\end{bmatrix} \times2$ + слои батч-нормализации\\
10--13. свёрточные слои $\begin{bmatrix}
3\times3\times256\\
3\times3\times256\\
\end{bmatrix} \times2$ + слои батч-нормализации\\
14--17. свёрточные слои $\begin{bmatrix}
3\times3\times512\\
3\times3\times512\\
\end{bmatrix} \times2$ + слои батч-нормализации\\
Average pool\\
18. полносвязный слой $512\times1000$\\

Итого 11 689 512 обучаемых параметров -- 44.7 Мб.

\subsubsection{ResNet-50}
На первом уровне ResNet-50 использует свёртку 7x7 с шагом 2, чтобы уменьшить входной сигнал до порядка, аналогично уровню пула. Затем следуют три residual блока перед повторной понижающей дискретизацией на 2. Так продолжается ещё несколько раз. После применяется average pooling, который создаёт 2048 признаков, усредняя данные каждой свёртки. Последний слой - полносвязный. В результате получается 1000-мерный вектор, который затем подаётся в слой Softmax.
\\

Архитектура по слоям:\\
1. свёрточный слой $7\times7\times64$ + слой батч-нормализации\\
Max pool\\
2--10. свёрточные слои $\begin{bmatrix}
1\times1\times64\\
3\times3\times64\\
1\times1\times256\\
\end{bmatrix} \times3$ + слои батч-нормализации\\
11--22. свёрточные слои $\begin{bmatrix}
1\times1\times128\\
3\times3\times128\\
1\times1\times512\\
\end{bmatrix} \times4$ + слои батч-нормализации\\
23--40. свёрточные слои $\begin{bmatrix}
1\times1\times256\\
3\times3\times256\\
1\times1\times1024\\
\end{bmatrix} \times3$ + слои батч-нормализации\\
41--49. свёрточные слои $\begin{bmatrix}
1\times1\times512\\
3\times3\times512\\
1\times1\times2048\\
\end{bmatrix} \times3$ + слои батч-нормализации\\
Average pool\\
50. полносвязный слой $2048\times1000$\\

Итого 25 557 032 обучаемых параметров -- 97.8 Мб.
\subsubsection{ResNeXt-101-32x8d}
На первом уровне ResNeXt-101 использует свёртку 7x7 с шагом 2, чтобы уменьшить входной сигнал до порядка, аналогично уровню пула. Затем следуют residual блоки, состоящие из 32 групп параллельных друг другу свёрток. После применяется average pooling, который создаёт 2048 признаков, усредняя данные каждой свёртки. Последний слой - полносвязный. В результате получается 1000-мерный вектор, который затем подаётся в слой Softmax.
\\

Архитектура по слоям:\\
1. свёрточный слой $7\times7\times64$ + слой батч-нормализации\\
Max pool\\
2--10. свёрточные слои $\begin{bmatrix}
1\times1\times256\\
3\times3\times256,& g=32\\
1\times1\times256\\
\end{bmatrix} \times3$ + слои батч-нормализации\\
11--22. свёрточные слои $\begin{bmatrix}
1\times1\times512\\
3\times3\times512,& g=32\\
1\times1\times512\\
\end{bmatrix} \times4$ + слои батч-нормализации\\
23--91. свёрточные слои $\begin{bmatrix}
1\times1\times1024\\
3\times3\times1024,& g=32\\
1\times1\times1024\\
\end{bmatrix} \times3$ + слои батч-нормализации\\
92--100. свёрточные слои $\begin{bmatrix}
1\times1\times2048\\
3\times3\times2048,& g=32\\
1\times1\times2048\\
\end{bmatrix} \times3$ + слои батч-нормализации\\
Average pool\\
101. полносвязный слой $2048\times1000$\\

Итого 88 791 336 обучаемых параметров -- 340 Мб.

\subsection{Маленький объём размеченных данных и бинарная классификация}
Взят датасет с чистыми и грязными тарелками, всего 40 размеченных изображений (по 20 каждого класса) и 744 изображения в тестовой выборке \cite{dsplates}. 

Для сравнения были реализованы: 
\begin{itemize*}
	\item Класс-обёртка для данных, модификация класса ImageFolder, функция записи форматированного результата в csv файл (Приложение~Б).
	\item Класс, обобщающий работу с моделями для классификации: создание модели, определение функции потерь и оптимизатора, обучение модели, валидация модели, сохранение и загрузка модели, построение графиков достоверности и ошибки, подсчёт метрик (достоверность, точность, полнота, F-мера), построение кривой ошибок и карт распределения предсказаний (Приложение~В).
\end{itemize*}
Все модели обучались с одинаковыми гиперпараметрами. Обучение длилось 100 эпох, а валидация проводилась через каждые 5 эпох (Приложение~Г). 

\subsubsection{ResNet-18}
Результаты обучения на разных этапах представлены на рисунке~\ref{cp18epoch}.

\begin{figure}[H]
	\begin{minipage}[h]{0.52\linewidth}
		\center{\includegraphics[width=1\linewidth]{cp18-1}} a) \\
	\end{minipage}
	\hfill
	\begin{minipage}[h]{0.46\linewidth}
		\center{\includegraphics[width=1\linewidth]{cp18-100}} \\b)
	\end{minipage}
	\caption{Результаты обучения ResNet-18: a) лучшая эпоха, b)
		последняя эпоха}
	\label{cp18epoch}
\end{figure}

Время обучения на 100 эпохах - $67$ минут. История изменения значения функции потерь и достоверности отражена на рисунке~\ref{cp18-loss}. 

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{cp18-loss}}
	\caption{Графики достоверности (слева) и функции потерь (справа)} 
	\label{cp18-loss} 
\end{figure}

Для выбора модели (последняя или лучшая по достоверности из истории обучения) построены их кривые ошибок (Рисунок~\ref{cp18-roc}). Кривая ошибки показывает зависимость ошибки от выбранного порогового значения, а площадь под графиком отражает качество модели независимо от выбора порога. Выбрана модель, полученная на 10 эпохе обучения.

\begin{figure}[H]
	\begin{minipage}[h]{0.49\linewidth}
		\center{\includegraphics[width=1\linewidth]{cp18-roc1}} a) \\
	\end{minipage}
	\hfill
	\begin{minipage}[h]{0.49\linewidth}
		\center{\includegraphics[width=1\linewidth]{cp18-roc100}} \\b)
	\end{minipage}
	\caption{Кривые ошибок: a) лучшая эпоха, b)
		последняя эпоха}
	\label{cp18-roc}
\end{figure}

Для выбора более точного порога рассчитаны метрики для разных пороговых значений (Рисунок~\ref{cp18-p}) и построены карты распределений (Рисунок~\ref{cp18-maps}). 

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{cp18-p1}} 
	\caption{Метрики (достоверность, точность, полнота, F-мера) для разных пороговых значений}
	\label{cp18-p}
\end{figure}

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{cp18-maps1}} 
	\caption{Карты распределения предсказаний при значении порога от 0,1 до 0,9}
	\label{cp18-maps}
\end{figure}

 Таким образом порог, обеспечивающий наилучшее качество равен $0.6$.  Среднее время для предсказания класса одного изображения занимает $0.239$ секунды.

\subsubsection{ResNet-50}
Результаты обучения на разных этапах представлены на рисунке~\ref{cp50epoch}.

\begin{figure}[H]
	\begin{minipage}[h]{0.55\linewidth}
		\center{\includegraphics[width=1\linewidth]{cp50-1}} a) \\
	\end{minipage}
	\hfill
	\begin{minipage}[h]{0.44\linewidth}
		\center{\includegraphics[width=1\linewidth]{cp50-100}} \\b)
	\end{minipage}
	\caption{Результаты обучения ResNet-50: a) лучшая эпоха, b)
		последняя эпоха}
	\label{cp50epoch}
\end{figure}

Время обучения на 100 эпохах - $181$ минута. История изменения значения функции потерь и достоверности отражена на рисунке~\ref{cp50-loss}. 

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{cp50-loss}}
	\caption{Графики достоверности (слева) и функции потерь (справа)} 
	\label{cp50-loss} 
\end{figure}

Для выбора модели (последняя или лучшая по достоверности из истории обучения) построены их кривые ошибок (Рисунок~\ref{cp50-roc}). Кривая ошибки показывает зависимость ошибки от выбранного порогового значения, а площадь под графиком отражает качество модели независимо от выбора порога. Выбрана модель, полученная на последней эпохе обучения.

\begin{figure}[H]
	\begin{minipage}[h]{0.49\linewidth}
		\center{\includegraphics[width=1\linewidth]{cp50-roc1}} a) \\
	\end{minipage}
	\hfill
	\begin{minipage}[h]{0.49\linewidth}
		\center{\includegraphics[width=1\linewidth]{cp50-roc100}} \\b)
	\end{minipage}
	\caption{Кривые ошибок: a) лучшая эпоха, b)
		последняя эпоха}
	\label{cp50-roc}
\end{figure}

Для выбора более точного порога рассчитаны метрики для разных пороговых значений (Рисунок~\ref{cp50-p}) и построены карты распределений (Рисунок~\ref{cp50-maps}). 

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{cp50-p100}} 
	\caption{Метрики (достоверность, точность, полнота, F-мера) для разных пороговых значений}
	\label{cp50-p}
\end{figure}

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{cp50-maps100}} 
	\caption{Карты распределения предсказаний при значении порога от 0,1 до 0,9}
	\label{cp50-maps}
\end{figure}

Таким образом порог, обеспечивающий наилучшее качество равен $0.8$.  Среднее время для предсказания класса одного изображения занимает $0.555$ секунды.

\subsubsection{ResNeXt-101-32x8d}
Результаты обучения на разных этапах представлены на рисунке~\ref{cp101epoch}.

\begin{figure}[H]
	\begin{minipage}[h]{0.55\linewidth}
		\center{\includegraphics[width=1\linewidth]{cp101-1}} a) \\
	\end{minipage}
	\hfill
	\begin{minipage}[h]{0.43\linewidth}
		\center{\includegraphics[width=1\linewidth]{cp101-100}} \\b)
	\end{minipage}
	\caption{Результаты обучения ResNeXt-101-32x8d: a) лучшая эпоха, b)
		последняя эпоха}
	\label{cp101epoch}
\end{figure}

Время обучения на 100 эпохах - $543$ минуты. История изменения значения функции потерь и достоверности отражена на рисунке~\ref{cp101-loss}. 

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{cp101-loss}}
	\caption{Графики достоверности (слева) и функции потерь (справа)} 
	\label{cp101-loss} 
\end{figure}

Для выбора модели (последняя или лучшая по достоверности из истории обучения) построены их кривые ошибок (Рисунок~\ref{cp101-roc}). Кривая ошибки показывает зависимость ошибки от выбранного порогового значения, а площадь под графиком отражает качество модели независимо от выбора порога. Выбрана модель, полученная на 20 эпохе обучения.

\begin{figure}[H]
	\begin{minipage}[h]{0.49\linewidth}
		\center{\includegraphics[width=1\linewidth]{cp101-roc1}} a) \\
	\end{minipage}
	\hfill
	\begin{minipage}[h]{0.49\linewidth}
		\center{\includegraphics[width=1\linewidth]{cp101-roc100}} \\b)
	\end{minipage}
	\caption{Кривые ошибок: a) лучшая эпоха, b)
		последняя эпоха}
	\label{cp101-roc}
\end{figure}

Для выбора более точного порога рассчитаны метрики для разных пороговых значений (Рисунокс) и построены карты распределений (Рисунок~\ref{cp101-maps}). 

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{cp101-p1}} 
	\caption{Метрики (достоверность, точность, полнота, F-мера) для разных пороговых значений}
	\label{cp101-p}
\end{figure}

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{cp101-maps1}} 
	\caption{Карты распределения предсказаний при значении порога от 0,1 до 0,9}
	\label{cp101-maps}
\end{figure}

Таким образом порог, обеспечивающий наилучшее качество равен $0.8$.  Среднее время для предсказания класса одного изображения занимает $1.752$ секунды.


\subsection{Многоклассовая классификация}
Взят набор данных Stanford Dogs, который содержит 20 580 изображений 120 пород собак. Так как этот набор данных был построен с использованием изображений и аннотаций из ImageNet для задачи детальной категоризации изображений \cite{dsdogs}, то вместо дообучения производится сравнение качества готовых моделей с учётом расположения этих 120 классов среди 1000 классов ImageNet \cite{dsdogsin}.

Для сравнения были реализованы: 
\begin{itemize*}
	\item модификация класса ImageFolder с учётом расположения классов пород собак в наборе данных ImageNet(Приложение~Б).
	\item Функция для оценки качества моделей: подсчёт метрик (достоверность, точность, полнота, F-мера), построение карт распределения предсказаний (Приложение~Д).
\end{itemize*}

\subsubsection{ResNet-18}
Достоверность составляет $0.8090$, среднее значение F-меры -- $0.8118$. 
Карты распределения предсказаний первых 30 классов представлены на рисунке~\ref{cd18-maps1}.

\subsubsection{ResNet-50}
Достоверность составляет $0.8784$, среднее значение F-меры -- $0.8790$.
Карты распределения предсказаний первых 30 классов представлены на рисунке~\ref{cd50-maps1}.


\subsubsection{ResNeXt-101-32x8d}
Достоверность составляет $0.9384$, среднее значение F-меры -- $0.9392$.
Карты распределения предсказаний первых 30 классов представлены на рисунке~\ref{cd101-maps1}.

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{cd18-maps1}} 
	\caption{Карты распределения предсказаний ResNet-18 для классов с 1 по 30}
	\label{cd18-maps1}
\end{figure}
\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{cd50-maps1}} 
	\caption{Карты распределения предсказаний ResNet-50 для классов с 1 по 30}
	\label{cd50-maps1}
\end{figure}
\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{cd101-maps1}} 
	\caption{Карты распределения предсказаний ResNeXt-101-32x8d для классов с 1 по 30}
	\label{cd101-maps1}
\end{figure}

\subsection{Результаты сравнения}
Результаты сравнения характеристик сведены в таблицу~\ref{tab:class}.
\begin{table}[H]
	\caption{результаты сравнения архитектур для классификации}
	\label{tab:class}
	\begin{tabular}{|p{0.2\linewidth}|p{0.2\linewidth}|p{0.15\linewidth}|p{0.15\linewidth}|p{0.18\linewidth}|} \hline
\multicolumn{2}{|p{0.4\linewidth}|}{}& ResNet-18 & ResNet-50 & ResNeXt-101 \\ \hline
\multicolumn{2}{|p{0.4\linewidth}|}{Количество слоёв} & 18 & 50 & 101 \\ \hline
\multicolumn{2}{|p{0.4\linewidth}|}{Количество параметров} & 11 689 512 & 22 557 032 & 88 791 336 \\ \hline
\multicolumn{2}{|p{0.4\linewidth}|}{Объём памяти} & 44.7 Мб & 97.8 Мб & 340 Мб \\ \hline
\multicolumn{2}{|p{0.4\linewidth}|}{Время предсказания} & 0.24 с & 0.56 с & 1.75 с \\ \hline
\multirow{4}{0.2\linewidth}{Бинарная классификация} & Достоверность & 0.797 & 0.808 & 0.868 \\
& Точность & 0.813 & 0.838 & 0.904 \\ 
& Полнота & 0.889 & 0.868 & 0.889 \\ 
& F--мера & 0.849 & 0.853 & 0.897 \\ \hline
\multirow{2}{0.2\linewidth}{Многоклассовая классификация} & Достоверность & 0.809 & 0.878 & 0.938 \\
& F--мера & 0.812 & 0.879 & 0.939 \\ \hline
	\end{tabular}
\end{table}

По результатам сравнения архитектура ResNeXt-101 показала лучшее качество на всех задачах, однако время предсказания на одном изображении у ResNeXt-101 примерно в 7 раз больше, чем у ResNet-18. Таким образом эта архитектура рекомендуется для задач, где необходима высокая точность,  но нет требований к скорости, например, анализ медицинских снимков. Помимо высокой скорости, ResNet-18 занимает небольшой объём в памяти, что делает её пригодной для использования на мобильных устройствах, в одноплатных компьютерах и в режиме реального времени. ResNet-50 представляет собой компромисс между точностью и скоростью, подходит для широкого спектра задач.