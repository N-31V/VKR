\newpage
\section{Исследование архитектур для локализации объектов на изображении}
В данной главе представлен обзор архитектур, сравнение по качеству работы на наборе данных COCO 2017 и нескольких произвольно выбранных изображениях.

\subsection{Сравнение архитектур}
Сравниваются две архитектуры Faster R-CNN и RetinaNet, основанные на уже рассмотренной архитектуре ResNeXt-101-32x8d. Изучению подлежит общая структура и характерные особенности сравниваемых решений.

\subsubsection{Faster R-CNN}
Схема архитектуры представлена на рисунке~\ref{faster_rcnn}.

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{faster_rcnn}}
	\caption{Архитектура faster R-CNN}
	\label{faster_rcnn}
\end{figure}

В качестве свёрточной сети для извлечения признаков используется ResNeXt-101-32x8d. Далее для каждой точки карты особенностей проверяется k претендентов разных размеров \cite{fasterrcnn}. Для этого используется Region Proposal Network (Рисунок~\ref{rpn}).

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{rpn}}
	\caption{Схема Region Proposal Network}
	\label{rpn}
\end{figure}

Как видно из схемы, карта особенностей, полученная от свёрточной сети, подаётся на свёрточный слой с ядром размера $3\times3$. А выход этого свёрточного слоя параллельно подаётся на два свёрточных слоя с ядром размера $1\times1$. Первый слой rpn\_cls\_score выдаёт k пар - вероятности наличия или отсутствия объекта в соответствующем регионе. Слой rpn\_bbox\_pred выдаёт k четвёрок - поправки для координат центра и размеров соответствующего региона претендента. 

Далее RoI pooling слой принимает на вход карту особенностей, полученную от последнего свёрточного слоя нейронной сети, и RoI претендента (в координатах изображения). RoI преобразуется из координат изображения в координаты на карте особенностей и на полученный прямоугольник накладывается сетка с наперёд заданными размерами. Делается max pooling по каждой ячейке этой сетки. Таким образом RoI pooling слой преобразует вектор особенностей произвольного прямоугольника из исходного изображения в вектор особенностей фиксированной размерности.

После RoI pooling слоя данные через два полносвязных слоя подаются параллельно на softmax слой для оценки принадлежности данного претендента одному из классов объектов и  слой реализующий регрессию, которая уточняет BBox объекта.

\subsubsection{RetinaNet}
RetinaNet (Рисунок~\ref{retina0}) представляет собой единую унифицированную сеть, состоящую из магистральной сети и двух специализированных подсетей \cite{retina2}. Магистраль отвечает за вычисление карты признаков по всему входному изображению и является собственной свёрточной сетью. Первая подсеть выполняет классификацию на выходе магистрали; вторая подсеть выполняет регрессию ограничивающего прямоугольника свёртки. 

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{retinanet}}
	\caption{Архитектура RetinaNet}
	\label{retina0}
\end{figure} 

Магистраль -- Feature Pyramid Network, построенная поверх ResNet. Классификационная подсеть предсказывает вероятность присутствия объекта в каждой пространственной позиции. Фокусная потеря применяется как функция потери. Подсеть блока регрессии выводит местоположение объекта относительно якорной рамки, если объект существует.

Feature Pyramid Network (Рисунок~\ref{retina1}) -- это структура для обнаружения объектов разных масштабов. Она заменяет средство извлечения признаков таких детекторов, как Faster R-CNN, и генерирует несколько слоёв карт признаков (многомасштабные карты признаков) с более качественной информацией, чем обычная пирамида признаков для обнаружения объектов \cite{fpn}.

\begin{figure}[H]
	\center{\includegraphics[width=0.8\linewidth]{retina1}}
	\caption{Схема Feature Pyramid Network}
	\label{retina1}
\end{figure}

FPN состоит из восходящего и нисходящего пути. Восходящий путь - это обычная свёрточная сеть для извлечения признаков. По мере подъёма пространственное разрешение уменьшается. При обнаружении большего количества высокоуровневых структур семантическое значение для каждого уровня увеличивается. FPN обеспечивает нисходящий путь для создания слоёв с более высоким разрешением из семантического обогащённого слоя. Хотя восстановленные слои семантически сильны, но расположение объектов не является точным после всех понижений и повышений. Поэтому добавлены боковые связи между реконструированными слоями и соответствующими картами признаков, чтобы помочь детектору прогнозировать местоположение лучше.

Focal Loss предназначен для решения одноэтапных проблем обнаружения объектов с дисбалансом, когда существует очень большое количество возможных классов фона и всего несколько классов переднего плана. Это приводит к тому, что обучение становится неэффективным, поскольку большинство местоположений представляют собой простые негативы, которые не дают полезного сигнала, а огромное количество этих негативных примеров подавляет обучение и снижает производительность модели. Фокусная потеря основана на перекрёстной энтропийной потере.

\subsection{Сравнение на наборе данных СОСО 2017}
Определимся с метриками для сравнения. Оценка достоверности - это вероятность того, что якорный ящик содержит объект. Обычно это предсказывается классификатором. Пересечение через объединение (IoU) определяется как площадь пересечения, делённая на площадь объединения предсказанного ограничивающего прямоугольника и истинного ограничивающего прямоугольника \cite{metr}.

Обнаружение считается истинно положительным (TP), только если оно удовлетворяет трём условиям: 
\begin{enumerate*}
	\item показатель достоверности больше порогового значения; 
	\item предсказанный класс соответствует истинному классу; 
	\item прогнозируемый ограничивающий прямоугольник имеет IoU, превышающий пороговое значение.
\end{enumerate*}

Нарушение любого из двух последних условий приводит к ложному положительному результату (FP). Когда показатель достоверности обнаружения,который должен обнаруживать объект, ниже порогового значения, обнаружение считается ложным отрицанием (FN). Когда показатель достоверности обнаружения, который не должен обнаруживать что-либо, ниже порогового значения, обнаружение считается истинно отрицательным (TN). 

С учётом этих правил достоверность, точность и полнота считаются обычным образом. 

Средняя точность (AP) основана на кривой точности-полноты. По сути, AP - это точность, усреднённая по всем уникальным уровням полноты.  Расчет AP включает только один класс, однако при обнаружении объектов обычно К>1 классов. Усреднённая средняя точность (mAP) определяется как среднее значение AP для всех К классов.

Задача COCO определяет несколько показателей mAP с использованием различных порогов, в том числе:

\begin{itemize*}
	\item mAP, который представляет собой mAP, усреднённый по 10 пороговым значениям IoU (т.е. 0.50, 0.55, 0.60, … , 0.95) и является первичной метрикой ;
	\item mAP50 (IoU = 0.5);
	\item mAP75 (IoU = 0.75);
	\item mAPs, который является mAP для небольших объектов, которые охватывают площадь менее $32^2$;
	\item mAPm, который является mAP для средних объектов, которые покрывают область больше, чем $32^2$,	но меньше чем $96^2$;
	\item mAPl, который является mAP для больших объектов, которые охватывают площадь больше $96^2$.
\end{itemize*}

Для изучения моделей использовалась библиотека mmdetection \cite{mmdetection}.

\subsubsection{Faster R-CNN}
Результаты валидации после 12 эпох обучения:
\begin{itemize*}
	\item $mAP = 0.412;$
	\item $mAP50 = 0.621;$
	\item $mAP75 = 0.451;$
	\item $mAPs = 0.240;$
	\item $mAPm = 0.455;$
	\item $mAPl = 0.535.$
\end{itemize*}

\subsubsection{RetinaNet}
Результаты валидации после 12 эпох обучения:
\begin{itemize*}
	\item $mAP = 0.399;$
	\item $mAP50 = 0.596;$
	\item $mAP75 = 0.427;$
	\item $mAPs = 0.223;$
	\item $mAPm = 0.442;$
	\item $mAPl = 0.525.$
\end{itemize*}

\subsection{Сравнение на произвольно выбранных изображениях}
Результаты сравнения на выбранных изображениях представлены на рисунках~\ref{loc1}--\ref{loc5}.

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{l1-f}}
	\caption{Предсказание Faster R-CNN на изображении 1} 
	\label{loc1}
\end{figure}
\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{l1-r}}
	\caption{Предсказание RetinaNet на изображении 1} 
\end{figure}

\begin{figure}[H]
	\begin{minipage}[h]{0.49\linewidth}
		\center{\includegraphics[width=1\linewidth]{l2-f}} a) \\
	\end{minipage}
	\hfill
	\begin{minipage}[h]{0.51\linewidth}
		\center{\includegraphics[width=1\linewidth]{l2-r}} \\b)
	\end{minipage}
	\caption{Предсказания на изображении 2: a) Faster R-CNN, b) RetinaNet}
\end{figure}

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{l3-f}}
	\caption{Предсказание Faster R-CNN на изображении 3} 
\end{figure}
\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{l3-r}}
	\caption{Предсказание RetinaNet на изображении 3} 
\end{figure}

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{l4-f}}
	\caption{Предсказание Faster R-CNN на изображении 4} 	
\end{figure}
\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{l4-r}}
	\caption{Предсказание RetinaNet на изображении 4} 
\end{figure}

\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{l5-f}}
	\caption{Предсказание Faster R-CNN на изображении 5} 	
\end{figure}
\begin{figure}[H]
	\center{\includegraphics[width=1\linewidth]{l5-r}}
	\caption{Предсказание RetinaNet на изображении 5} 
	\label{loc5}
\end{figure}

\subsection{Результаты сравнения}
В ходе сравнения обнаружено, что RetinaNet плохо обнаруживает крупные объекты, а также хуже обнаруживает разнообразные классы, но неплохо справляется с задачами обнаружения маленьких машин и людей. Время распознавания у Faster R-CNN незначительно меньше (на 2-3 секунды, при времени распознавания одного изображения около 30 секунд), а размер обученной модели незначительно больше (на 15 Мб, при среднем весе модели в 235 Мб). Итого экспериментальное сравнение на произвольной выборке подтверждает преимущество Faster R-CNN, полученное при валидации на наборе данных COCO. Таким образом из архитектур Faster R-CNN и RetinaNet, основанных на ResNeXt-101-32x8d и обученных на наборе данных COCO, для большинства задач рекомендуется использовать Faster R-CNN, исключением могут быть такие специфические задачи, как распознавание мелких объектов с воздуха.